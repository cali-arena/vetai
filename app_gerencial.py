"""
VetDiagnosisAI - App Gerencial
Dashboard para monitorar performance, acur√°cia e retreinar modelo
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from datetime import datetime, timedelta
import joblib
import json
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="VetDiagnosisAI - Dashboard Gerencial",
    page_icon="üìä",
    layout="wide"
)

# CSS personalizado
st.markdown("""
<style>
    .metric-card {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem 0;
    }
    .success-card {
        background: linear-gradient(90deg, #11998e 0%, #38ef7d 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem 0;
    }
    .warning-card {
        background: linear-gradient(90deg, #f093fb 0%, #f5576c 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Header
st.title("üìä VetDiagnosisAI - Dashboard Gerencial")
st.markdown("### Monitoramento de Performance e Gest√£o do Modelo")

# Sidebar para navega√ß√£o
st.sidebar.title("üéõÔ∏è Controles")
pagina = st.sidebar.selectbox(
    "Selecione a p√°gina:",
    ["üìà Vis√£o Geral", "ü§ñ Treinar Modelo", "üìä Analytics", "‚öôÔ∏è Configura√ß√µes"]
)

# Fun√ß√£o para carregar dados reais
@st.cache_data
def carregar_dados_reais():
    """Carrega dados reais da pasta data"""
    try:
        data_path = Path("data")
        if not data_path.exists():
            return None
            
        csv_files = list(data_path.glob("*.csv"))
        if not csv_files:
            return None
            
        # Priorizar datasets espec√≠ficos
        datasets_prioritarios = [
            'veterinary_complete_real_dataset.csv',
            'veterinary_master_dataset.csv', 
            'veterinary_realistic_dataset.csv',
            'clinical_veterinary_data.csv',
            'laboratory_complete_panel.csv'
        ]
        
        for dataset_name in datasets_prioritarios:
            dataset_path = data_path / dataset_name
            if dataset_path.exists():
                df = pd.read_csv(dataset_path)
                if len(df) > 0:
                    return df, dataset_name
                    
        # Se n√£o encontrar os priorit√°rios, usar qualquer CSV
        if csv_files:
            df = pd.read_csv(csv_files[0])
            return df, csv_files[0].name
            
        return None
    except Exception as e:
        st.error(f"Erro ao carregar dados: {e}")
        return None

# Fun√ß√£o para carregar logs de predi√ß√µes
def carregar_logs():
    """Carrega logs de predi√ß√µes (simulado por enquanto)"""
    logs_path = Path("logs/predictions.json")
    if logs_path.exists():
        try:
            with open(logs_path, 'r') as f:
                return json.load(f)
        except:
            return []
    return []

# Fun√ß√£o para salvar logs
def salvar_log(log_data):
    """Salva log de predi√ß√£o"""
    logs_path = Path("logs")
    logs_path.mkdir(exist_ok=True)
    
    logs = carregar_logs()
    logs.append(log_data)
    
    # Manter apenas √∫ltimos 1000 logs
    if len(logs) > 1000:
        logs = logs[-1000:]
    
    with open(logs_path / "predictions.json", 'w') as f:
        json.dump(logs, f, indent=2)

# P√°gina: Vis√£o Geral
if pagina == "üìà Vis√£o Geral":
    st.header("üìà Vis√£o Geral do Sistema")
    
    # M√©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    
    # Carregar dados para estat√≠sticas
    dados_result = carregar_dados_reais()
    if dados_result:
        df, dataset_name = dados_result
        total_registros = len(df)
        total_diagnosticos = df['diagnostico'].nunique() if 'diagnostico' in df.columns else 0
    else:
        total_registros = 0
        total_diagnosticos = 0
    
    # Carregar informa√ß√µes do modelo atual
    model_path = Path("models/gb_optimized_model.pkl")
    if model_path.exists():
        try:
            model_data = joblib.load(model_path)
            accuracy_atual = model_data.get('accuracy', 0)
            ultima_atualizacao = model_data.get('timestamp', 'N/A')
        except:
            accuracy_atual = 0
            ultima_atualizacao = 'N/A'
    else:
        accuracy_atual = 0
        ultima_atualizacao = 'Nunca'
    
    with col1:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric("üìä Total de Registros", f"{total_registros:,}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric("üè• Diagn√≥sticos √önicos", total_diagnosticos)
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col3:
        color_class = "success-card" if accuracy_atual >= 0.85 else "warning-card"
        st.markdown(f'<div class="{color_class}">', unsafe_allow_html=True)
        st.metric("üéØ Acur√°cia Atual", f"{accuracy_atual:.1%}")
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col4:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric("üîÑ √öltima Atualiza√ß√£o", ultima_atualizacao.split('T')[0] if 'T' in ultima_atualizacao else ultima_atualizacao)
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Status do modelo
    st.subheader("üéØ Status do Modelo")
    
    if accuracy_atual >= 0.85:
        st.success("‚úÖ **Modelo em Excelente Estado!** Acur√°cia >= 85%")
    elif accuracy_atual >= 0.75:
        st.warning("‚ö†Ô∏è **Modelo Aceit√°vel** - Considere retreinar para melhorar performance")
    else:
        st.error("‚ùå **Modelo Precisa de Atualiza√ß√£o** - Acur√°cia abaixo de 75%")
    
    # Gr√°ficos de performance
    if dados_result:
        df, dataset_name = dados_result
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Distribui√ß√£o de diagn√≥sticos
            if 'diagnostico' in df.columns:
                diag_counts = df['diagnostico'].value_counts().head(10)
                fig = px.pie(
                    values=diag_counts.values,
                    names=diag_counts.index,
                    title="Top 10 Diagn√≥sticos Mais Frequentes"
                )
                st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Distribui√ß√£o por esp√©cie
            if 'especie' in df.columns:
                especie_counts = df['especie'].value_counts()
                fig = px.bar(
                    x=especie_counts.index,
                    y=especie_counts.values,
                    title="Distribui√ß√£o por Esp√©cie"
                )
                st.plotly_chart(fig, use_container_width=True)

# P√°gina: Treinar Modelo
elif pagina == "ü§ñ Treinar Modelo":
    st.header("ü§ñ Treinamento do Modelo")
    
    dados_result = carregar_dados_reais()
    if not dados_result:
        st.error("‚ùå Nenhum dataset encontrado na pasta 'data/'. Adicione dados reais para treinar o modelo.")
        st.stop()
    
    df, dataset_name = dados_result
    st.success(f"‚úÖ Dataset carregado: {dataset_name} ({len(df)} registros)")
    
    # Configura√ß√µes de treinamento
    st.subheader("‚öôÔ∏è Configura√ß√µes de Treinamento")
    
    col1, col2 = st.columns(2)
    
    with col1:
        use_advanced_features = st.checkbox("üîß Feature Engineering Avan√ßado", value=True)
        use_feature_selection = st.checkbox("üéØ Sele√ß√£o de Features", value=True)
        test_size = st.slider("üìä Tamanho do Teste", 0.1, 0.4, 0.2, 0.05)
    
    with col2:
        use_hyperparameter_tuning = st.checkbox("‚öôÔ∏è Otimiza√ß√£o de Hiperpar√¢metros", value=True)
        cv_folds = st.slider("üîÑ Valida√ß√£o Cruzada (folds)", 3, 10, 5)
        random_state = st.number_input("üé≤ Random State", 1, 1000, 42)
    
    # Bot√£o para treinar
    if st.button("üöÄ Treinar Modelo", type="primary", use_container_width=True):
        
        with st.spinner("üîÑ Preparando dados..."):
            # Preparar dados
            df_ml = df.copy()
            
            # Codifica√ß√£o
            le_especie = LabelEncoder()
            le_sexo = LabelEncoder()
            le_diagnostico = LabelEncoder()
            
            if 'especie' in df_ml.columns:
                df_ml['especie_encoded'] = le_especie.fit_transform(df_ml['especie'])
            if 'sexo' in df_ml.columns:
                df_ml['sexo_encoded'] = le_sexo.fit_transform(df_ml['sexo'])
            df_ml['diagnostico_encoded'] = le_diagnostico.fit_transform(df_ml['diagnostico'])
            
            # Feature engineering
            if use_advanced_features:
                # Criar features derivadas
                if 'idade_anos' in df_ml.columns:
                    df_ml['idade_categoria'] = pd.cut(df_ml['idade_anos'], bins=[0, 1, 3, 7, 12, 100], labels=[0, 1, 2, 3, 4])
                    df_ml['idade_senior'] = (df_ml['idade_anos'] > 7).astype(int)
                
                # Criar features de sintomas
                sintoma_cols = [col for col in df_ml.columns if col in ['febre', 'apatia', 'perda_peso', 'vomito', 'diarreia', 'tosse', 'letargia', 'feridas_cutaneas', 'poliuria', 'polidipsia']]
                if sintoma_cols:
                    df_ml['total_sintomas'] = df_ml[sintoma_cols].sum(axis=1)
            
            # Selecionar features num√©ricas
            numeric_cols = df_ml.select_dtypes(include=[np.number]).columns.tolist()
            if 'diagnostico_encoded' in numeric_cols:
                numeric_cols.remove('diagnostico_encoded')
            
            X = df_ml[numeric_cols].fillna(0)
            y = df_ml['diagnostico_encoded']
            
            # Feature selection
            if use_feature_selection:
                from sklearn.feature_selection import SelectKBest, f_classif
                k_best = min(30, X.shape[1])
                selector = SelectKBest(score_func=f_classif, k=k_best)
                X = selector.fit_transform(X, y)
        
        with st.spinner("üîÑ Dividindo dados..."):
            # Dividir dados
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=y
            )
            
            # Escalar
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
        
        with st.spinner("üîÑ Treinando modelo..."):
            # Configurar modelo
            gb_params = {
                'n_estimators': 1000,
                'learning_rate': 0.01,
                'max_depth': 12,
                'min_samples_split': 2,
                'min_samples_leaf': 1,
                'subsample': 0.8,
                'random_state': random_state
            }
            
            # Otimiza√ß√£o de hiperpar√¢metros
            if use_hyperparameter_tuning:
                param_grid = {
                    'n_estimators': [800, 1000, 1200],
                    'learning_rate': [0.005, 0.01, 0.02],
                    'max_depth': [10, 12, 15],
                    'subsample': [0.7, 0.8, 0.9]
                }
                
                gb_base = GradientBoostingClassifier(random_state=random_state)
                random_search = RandomizedSearchCV(
                    gb_base, param_grid, n_iter=15, cv=cv_folds, 
                    scoring='accuracy', random_state=random_state, n_jobs=-1
                )
                random_search.fit(X_train_scaled, y_train)
                gb_params.update(random_search.best_params_)
            
            # Treinar modelo final
            gb_model = GradientBoostingClassifier(**gb_params)
            gb_model.fit(X_train_scaled, y_train)
            
            # Predi√ß√µes
            y_pred = gb_model.predict(X_test_scaled)
            accuracy = accuracy_score(y_test, y_pred)
            
            # Valida√ß√£o cruzada
            cv_scores = cross_val_score(gb_model, X_train_scaled, y_train, cv=cv_folds)
            cv_mean = cv_scores.mean()
            cv_std = cv_scores.std()
        
        # Salvar modelo
        with st.spinner("üíæ Salvando modelo..."):
            model_data = {
                'model': gb_model,
                'scaler': scaler,
                'le_diagnostico': le_diagnostico,
                'le_especie': le_especie,
                'le_sexo': le_sexo,
                'accuracy': accuracy,
                'cv_mean': cv_mean,
                'cv_std': cv_std,
                'timestamp': datetime.now().isoformat(),
                'training_samples': len(X_train),
                'test_samples': len(X_test),
                'features_used': numeric_cols[:X.shape[1]] if use_feature_selection else numeric_cols
            }
            
            model_path = Path("models")
            model_path.mkdir(exist_ok=True)
            joblib.dump(model_data, model_path / "gb_optimized_model.pkl")
        
        # Mostrar resultados
        st.success("‚úÖ Modelo treinado e salvo com sucesso!")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("üéØ Acur√°cia", f"{accuracy:.1%}")
        with col2:
            st.metric("üìä CV Mean", f"{cv_mean:.3f}")
        with col3:
            st.metric("üìà CV Std", f"{cv_std:.3f}")
        
        # Status da meta
        if accuracy >= 0.85:
            st.success(f"üéâ **META ALCAN√áADA!** Acur√°cia de {accuracy:.1%} >= 85%!")
        else:
            st.warning(f"üéØ Meta: 85% | Atual: {accuracy:.1%} | Faltam: {(0.85-accuracy)*100:.1f}%")

# P√°gina: Analytics
elif pagina == "üìä Analytics":
    st.header("üìä Analytics e Monitoramento")
    
    # Carregar logs
    logs = carregar_logs()
    
    if not logs:
        st.info("üìä Nenhum log de predi√ß√µes encontrado ainda.")
        st.info("üí° Use o app de predi√ß√£o para gerar dados de analytics.")
    else:
        st.success(f"üìä {len(logs)} predi√ß√µes registradas")
        
        # Converter logs para DataFrame
        df_logs = pd.DataFrame(logs)
        df_logs['timestamp'] = pd.to_datetime(df_logs['timestamp'])
        
        # M√©tricas de uso
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üìä Total de Predi√ß√µes", len(df_logs))
        
        with col2:
            predicoes_hoje = len(df_logs[df_logs['timestamp'].dt.date == datetime.now().date()])
            st.metric("üìÖ Predi√ß√µes Hoje", predicoes_hoje)
        
        with col3:
            confianca_media = df_logs['confianca'].mean()
            st.metric("üéØ Confian√ßa M√©dia", f"{confianca_media:.1f}%")
        
        with col4:
            especies_unicas = df_logs['especie'].nunique()
            st.metric("üêæ Esp√©cies Atendidas", especies_unicas)
        
        # Gr√°ficos de analytics
        col1, col2 = st.columns(2)
        
        with col1:
            # Predi√ß√µes por dia
            df_daily = df_logs.groupby(df_logs['timestamp'].dt.date).size().reset_index(name='predicoes')
            fig = px.line(df_daily, x='timestamp', y='predicoes', title='Predi√ß√µes por Dia')
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Distribui√ß√£o de diagn√≥sticos
            diag_counts = df_logs['diagnostico_predito'].value_counts().head(10)
            fig = px.bar(diag_counts, title='Top 10 Diagn√≥sticos Mais Preditos')
            st.plotly_chart(fig, use_container_width=True)
        
        # Tabela de logs recentes
        st.subheader("üìã Predi√ß√µes Recentes")
        df_recent = df_logs.tail(20)[['timestamp', 'especie', 'idade', 'diagnostico_predito', 'confianca']]
        st.dataframe(df_recent, use_container_width=True)

# P√°gina: Configura√ß√µes
elif pagina == "‚öôÔ∏è Configura√ß√µes":
    st.header("‚öôÔ∏è Configura√ß√µes do Sistema")
    
    # Configura√ß√µes do modelo
    st.subheader("ü§ñ Configura√ß√µes do Modelo")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("**Configura√ß√µes Atuais:**")
        model_path = Path("models/gb_optimized_model.pkl")
        if model_path.exists():
            model_data = joblib.load(model_path)
            st.write(f"‚úÖ Modelo carregado")
            st.write(f"üìä Acur√°cia: {model_data.get('accuracy', 0):.1%}")
            st.write(f"üïí √öltima atualiza√ß√£o: {model_data.get('timestamp', 'N/A')}")
        else:
            st.write("‚ùå Nenhum modelo encontrado")
    
    with col2:
        st.info("**A√ß√µes Dispon√≠veis:**")
        if st.button("üîÑ Retreinar Modelo", type="primary"):
            st.info("Use a aba 'Treinar Modelo' para retreinar")
        
        if st.button("üìä Verificar Performance"):
            st.info("Analisando performance atual...")
        
        if st.button("üßπ Limpar Logs"):
            logs_path = Path("logs/predictions.json")
            if logs_path.exists():
                logs_path.unlink()
                st.success("Logs limpos!")
    
    # Configura√ß√µes do sistema
    st.subheader("üîß Configura√ß√µes do Sistema")
    
    auto_retrain = st.checkbox("üîÑ Retreinamento Autom√°tico", value=False, help="Retreinar modelo automaticamente quando acur√°cia < 75%")
    log_predictions = st.checkbox("üìä Log de Predi√ß√µes", value=True, help="Registrar todas as predi√ß√µes para analytics")
    email_alerts = st.checkbox("üìß Alertas por Email", value=False, help="Enviar alertas quando acur√°cia cair")
    
    if st.button("üíæ Salvar Configura√ß√µes"):
        config = {
            'auto_retrain': auto_retrain,
            'log_predictions': log_predictions,
            'email_alerts': email_alerts
        }
        
        config_path = Path("config.json")
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        
        st.success("‚úÖ Configura√ß√µes salvas!")

# Footer
st.divider()
st.markdown("""
<div style="text-align: center; color: #666; margin-top: 2rem;">
    <p>üìä VetDiagnosisAI - Dashboard Gerencial</p>
    <p><small>Sistema de monitoramento e gest√£o do modelo de diagn√≥stico veterin√°rio</small></p>
</div>
""", unsafe_allow_html=True)
